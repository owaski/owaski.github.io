---
---

@misc{ouyang2025infinisstsimultaneoustranslationunbounded,
    abbr={Preprint},
    title={InfiniSST: Simultaneous Translation of Unbounded Speech with Large Language Model}, 
    author={Siqi Ouyang and Xi Xu and Lei Li},
    abstract={Simultaneous translation of unbounded streaming speech remains a challenging problem due to the need for effectively processing the history speech context and past translations so that quality and latency, including computation overhead, can be balanced. Most prior works assume pre-segmented speech, limiting their real-world applicability. In this paper, we propose InfiniSST, a novel approach that formulates SST as a multi-turn dialogue task, enabling seamless translation of unbounded speech. We construct translation trajectories and robust segments from MuST-C with multi-latency augmentation during training and develop a key-value (KV) cache management strategy to facilitate efficient inference. Experiments on MuST-C En-Es, En-De, and En-Zh demonstrate that InfiniSST reduces computation-aware latency by 0.5 to 1 second while maintaining the same translation quality compared to baselines. Ablation studies further validate the contributions of our data construction and cache management strategy.},
    year={2025},
    month={Mar},
    eprint={2503.02969},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    pdf={https://www.arxiv.org/pdf/2503.02969}, 
    selected={true},
    code={https://github.com/LeiLiLab/InfiniSST},
}

@inproceedings{ouyang-etal-2025-anticipating,
    abbr={NAACL},
    title = "Anticipating Future with Large Language Model for Simultaneous Machine Translation",
    author = "Ouyang, Siqi  and
      Hrinchuk, Oleksii  and
      Chen, Zhehuai  and
      Lavrukhin, Vitaly  and
      Balam, Jagadeesh  and
      Li, Lei  and
      Ginsburg, Boris",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.naacl-long.286/",
    pages = "5547--5557",
    ISBN = "979-8-89176-189-6",
    abstract = "Simultaneous machine translation (SMT) takes streaming input utterances and incrementally produces target text. Existing SMT methods only use the partial utterance that has already arrived at the input and the generated hypothesis. Motivated by human interpreters' technique to forecast future words before hearing them, we propose Translation by Anticipating Future (TAF), a method to improve translation quality while retaining low latency. Its core idea is to use a large language model (LLM) to predict future source words and opportunistically translate without introducing too much risk. We evaluate our TAF and multiple baselines of SMT on four language directions. Experiments show that TAF achieves the best translation quality-latency trade-off and outperforms the baselines by up to 5 BLEU points at the same latency (three words).",
    pdf={https://aclanthology.org/2025.naacl-long.286.pdf},
    code={https://github.com/owaski/TAF},
    selected={true},
}

@inproceedings{xu-etal-2025-ca,
    abbr={NAACL},
    title = "{CA}*: Addressing Evaluation Pitfalls in Computation-Aware Latency for Simultaneous Speech Translation",
    author = "Xu, Xi  and
      Xu, Wenda  and
      Ouyang, Siqi  and
      Li, Lei",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2025",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-naacl.393/",
    pages = "7062--7067",
    ISBN = "979-8-89176-195-7",
    abstract = "Simultaneous speech translation (SimulST) systems must balance translation quality with response time, making latency measurement crucial for evaluating their real-world performance. However, there has been a longstanding belief that current metrics yield unrealistically high latency measurements in unsegmented streaming settings. In this paper, we investigate this phenomenon, revealing its root cause in a fundamental misconception underlying existing latency evaluation approaches. We demonstrate that this issue affects not only streaming but also segment-level latency evaluation across different metrics. Furthermore, we propose a modification to correctly measure computation-aware latency for SimulST systems, addressing the limitations present in existing metrics.",
      pdf={https://arxiv.org/pdf/2410.16011},
      selected={true},
}

@misc{ouyang2024fasstfastllmbasedsimultaneous,
abbr={Preprint},
      title={FASST: Fast LLM-based Simultaneous Speech Translation}, 
      author={Siqi Ouyang and Xi Xu and Chinmay Dandekar and Lei Li},
      year={2024},
      eprint={2408.09430},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      month={Aug},
      url={https://arxiv.org/abs/2408.09430}, 
      abstract={Simultaneous speech translation (SST) takes streaming speech input and generates text translation on the fly. Existing methods either have high latency due to recomputation of input representations, or fall behind of offline ST in translation quality. In this paper, we propose FASST, a fast large language model based method for streaming speech translation. We propose blockwise-causal speech encoding and consistency mask, so that streaming speech input can be encoded incrementally without recomputation. Furthermore, we develop a two-stage training strategy to optimize FASST for simultaneous inference. We evaluate FASST and multiple strong prior models on MuST-C dataset. Experiment results show that FASST achieves the best quality-latency trade-off. It outperforms the previous best model by an average of 1.5 BLEU under the same latency for English to Spanish translation.},
      pdf={https://arxiv.org/pdf/2408.09430},
      selected={true},
}

@inproceedings{xu-etal-2024-cmus,
    title = "{CMU}`s {IWSLT} 2024 Simultaneous Speech Translation System",
    author = "Xu, Xi  and
      Ouyang, Siqi  and
      Yan, Brian  and
      Fernandes, Patrick  and
      Chen, William  and
      Li, Lei  and
      Neubig, Graham  and
      Watanabe, Shinji",
    editor = "Salesky, Elizabeth  and
      Federico, Marcello  and
      Carpuat, Marine",
    booktitle = "Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand (in-person and online)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.iwslt-1.20/",
    doi = "10.18653/v1/2024.iwslt-1.20",
    pages = "154--159",
    abstract = "This paper describes CMU`s submission to the IWSLT 2024 Simultaneous Speech Translation (SST) task for translating English speech to German text in a streaming manner. Our end-to-end speech-to-text (ST) system integrates the WavLM speech encoder, a modality adapter, and the Llama2-7B-Base model as the decoder. We employ a two-stage training approach: initially, we align the representations of speech and text, followed by full fine-tuning. Both stages are trained on MuST-c v2 data with cross-entropy loss. We adapt our offline ST model for SST using a simple fixed hold-n policy. Experiments show that our model obtains an offline BLEU score of 31.1 and a BLEU score of 29.5 under 2 seconds latency on the MuST-C-v2 tst-COMMON.",
    pdf={https://aclanthology.org/2024.iwslt-1.20.pdf},
    comment={Top 1 Human Rating},
    selected={true},
}